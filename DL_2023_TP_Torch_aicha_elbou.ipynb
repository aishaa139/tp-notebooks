{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dbbdca17-672d-4375-ad89-8a533a25b350",
      "metadata": {
        "id": "dbbdca17-672d-4375-ad89-8a533a25b350"
      },
      "source": [
        "## Initiation au CNN avec Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EVJNEQ--lOW"
      },
      "source": [
        "Ce TP s'effectue individuellement ou en binome. Veuillez respecter les consignes suivantes pour le rendu de votre travail :\n",
        "\n",
        "* Renommez le selon le format suivant : \"DL_2023_TP_Torch_prenom1_nom1_prenom2_nom2.ipynb\".\n",
        "* Veillez à ce que votre nom et prénom soient complétés dans la cellule ci-dessous.\n",
        "* Veillez à avoir bien exécuté toutes les cellules de code et que les résultats soient tous bien visible dans le notebook sans nécessiter une ré-exécution.\n",
        "* Partagez le notebook avec hana.sebia@univ-lyon1.fr"
      ],
      "id": "2EVJNEQ--lOW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEXbbYkX-lOX"
      },
      "source": [
        "Veuillez compléter vos noms et prénoms ci-dessous :\n",
        "\n",
        "*   **Prenom 1** : Aicha\n",
        "*   **Nom 1** : EL BOU"
      ],
      "id": "SEXbbYkX-lOX"
    },
    {
      "cell_type": "markdown",
      "id": "ccfd3b73-0063-4f28-b0dd-e062305be9a1",
      "metadata": {
        "id": "ccfd3b73-0063-4f28-b0dd-e062305be9a1"
      },
      "source": [
        "Ce TP est une introduction au framework Pytorch. Nous allons construire une des premières architectures de CNN présenté par [Yann Le Cun](https://fr.wikipedia.org/wiki/Yann_Le_Cun), un [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf).\n",
        "\n",
        "L'architecture du LeNet est détaillée dans la figure ci-dessous:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "943a5684-8aa0-46f1-a0f4-408854af6809",
      "metadata": {
        "id": "943a5684-8aa0-46f1-a0f4-408854af6809"
      },
      "source": [
        "![leNet5.jpeg](leNet5.jpeg \"Architecture Lenet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "245854e7-42be-4ec4-9d7d-63370fc3b18a",
      "metadata": {
        "id": "245854e7-42be-4ec4-9d7d-63370fc3b18a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd69d7f-0715-4515-fff7-7a254abdb108"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d8f5c16d090>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# on importe les bibliothèques pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07d4e646",
      "metadata": {
        "id": "07d4e646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5431663-d395-40f9-a796-640dc8092856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA device not found.\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print (\"CUDA device not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d332ec33-92dc-45ab-9a7d-91754256cf57",
      "metadata": {
        "id": "d332ec33-92dc-45ab-9a7d-91754256cf57"
      },
      "source": [
        "### Chargement du jeu de données\n",
        "La tâche que nous souhaitons réaliser est la classification d'image [MNIST](https://fr.wikipedia.org/wiki/Base_de_donn%C3%A9es_MNIST). La base de données MNIST (Modified National Institute of Standards and Technology) est une base de données de chiffres écrits à la main. C'est un jeu de données très utlisé en apprentissage automatique. Il regroupe 60000 images d'apprentissage et 10000 images de test. On peut télécharger ces données à partir du module dataset de torchvision en séparant le chargement du train/test set. Il est également possible d'appliquer un ensemble de transformations aux images dès le chargement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "460f3a0b-0108-4614-8acf-1c1ac0d02588",
      "metadata": {
        "id": "460f3a0b-0108-4614-8acf-1c1ac0d02588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533492bf-d8ad-4063-99bf-092d5ec881d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 109522459.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 30337013.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 31992836.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14722201.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms # On peut importer directement le dataset de pytorch\n",
        "\n",
        "# On définit transforms qui permet de redimensionner l'image en 32*32 et de la transformer en tensor\n",
        "transforms = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# On télécharge et on créer la dataset d'entraienement à l'aide du module datasets de torchvision\n",
        "train_dataset = datasets.MNIST(root='mnist_data',\n",
        "                               train=True,\n",
        "                               transform=transforms,\n",
        "                               download=True)\n",
        "\n",
        "# On télécharge et on créer la dataset de test à l'aide du module datasets de torchvision\n",
        "valid_dataset = datasets.MNIST(root='mnist_data',\n",
        "                               train=False,\n",
        "                               transform=transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCpMt3iu-lOa"
      },
      "source": [
        "Une fois les train/test sets chargés, on définit des dataloaders qui permettent de créer des batchs pour la phase train de l'apprentissage de notre modèle comme suit :"
      ],
      "id": "VCpMt3iu-lOa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zBqZPkZ-lOa"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32 #taille du batch size\n",
        "\n",
        "# On définit le data loaders d'entraienement . Le data loaders permet de créer des batchs. On doit lui renseigner le batch size.\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True)\n",
        "# On définit le data loaders de validation .\n",
        "valid_loader = DataLoader(dataset=valid_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False)"
      ],
      "id": "2zBqZPkZ-lOa"
    },
    {
      "cell_type": "markdown",
      "id": "92b41a7f-a59c-48fe-9ed6-e9d3d5e6e976",
      "metadata": {
        "id": "92b41a7f-a59c-48fe-9ed6-e9d3d5e6e976"
      },
      "source": [
        "### Définition du modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1e6e95b-1135-4325-b4ce-1a9374350d15",
      "metadata": {
        "id": "c1e6e95b-1135-4325-b4ce-1a9374350d15"
      },
      "source": [
        "---\n",
        "<span style='color:Green'>**Question**</span>\n",
        "\n",
        "Implémenter la classe LeNet avec l'architecture proposée en utilisant l’interface [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) de PyTorch:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Dans l'initialisation de la classe LeNet\n",
        "1. La première couche [convolutive](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) avec 6 noyaux de taille 5×5 et le stride de 1.\n",
        "2. Une couche de [sous-échantillonnage/mise](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html) en commun avec 6 noyaux de taille 2×2.\n",
        "3. La deuxième couche convolutive avec la même configuration que la première, cette fois avec 16 filtres. La sortie de cette couche est de 10×10×16.\n",
        "4. La deuxième couche de mise en commun. La logique est identique à celle de la précédente, mais cette fois, la couche comporte 16 filtres. La sortie de cette couche est de taille 5×5×16.\n",
        "5. La dernière couche convolutive avec 120 noyaux 5×5.\n",
        "6. La dernière couche est un réseau de [neurones simple](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) comme détaillé dans l'architecture ci-dessus.\n",
        "\n",
        "Toute couche convolutive doit être suivi d'une [ normalisation](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d) et d'une fonction d'activation [ReLu](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#relu)\n",
        "\n",
        "Dans la fonction forward de la classe LeNet définissez le passage de la donnée x en appliquant à la fin un [softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html) pour calculer la probabilité d'appartenance à la classe des chiffres de mnist.\n",
        "\n",
        "\n",
        "**Indice**\n",
        "Indice: l’utilisation de la méthode [.view()](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) ou de la couche [nn.Flatten()](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) peut être utile pour ré-arranger les tenseurs avant ou après les couches linéaires. Par exemple, x.view(-1, 1, 28, 28) permet de transformer un tenseur de dimensions 784 en un tenseur de dimensions (batch, 1, 28, 28)…"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            # Couche 1\n",
        "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.ReLU(),\n",
        "            # Couche 2\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Couche 3\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            # Couche 4\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # La dernière couche convolutive avec 120 noyaux 5×5.\n",
        "        self.last_conv = nn.Sequential(\n",
        "            nn.Conv2d(16, 120, kernel_size=5, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(120),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        #la dernière couche est un réseau de neurones simple comme détaillé dans l'architecture ci-dessus.\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.last_conv(x)\n",
        "\n",
        "        #utilisation de la méthode .view() pour ré-arranger les tenseurs\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        #qappliquer softmax pour obtenir les probabilités d'appartenance à la classe\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        return logits, probs\n",
        "\n",
        "# Instancier le modèle LeNet\n",
        "net = LeNet()\n",
        "print(net)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWaH-iGh_ov-",
        "outputId": "b42aea41-cc70-48f8-ed93-7caaee39126d"
      },
      "id": "yWaH-iGh_ov-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet(\n",
            "  (feature_extractor): Sequential(\n",
            "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (last_conv): Sequential(\n",
            "    (0): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=84, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62a86236-6bc4-40ee-9bea-bc4cc787fd45",
      "metadata": {
        "id": "62a86236-6bc4-40ee-9bea-bc4cc787fd45"
      },
      "source": [
        "---\n",
        "<span style='color:Green'>**Question**</span>\n",
        "\n",
        "Compléter et commenter la fonction train(chaque ligne du code), celle-ci permet d'entrainer votre modèle:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d7d9eda-d9ae-4858-ae9c-c5795fee7a01",
      "metadata": {
        "id": "5d7d9eda-d9ae-4858-ae9c-c5795fee7a01"
      },
      "outputs": [],
      "source": [
        "# On créer la fonction qui permet d'entrainer le modèle\n",
        "def train(train_loader, model, criterion, optimizer):\n",
        "    '''\n",
        "    Function for the training step of the training loop\n",
        "    '''\n",
        "    model.train()  # Met le modèle en mode d'entraînement\n",
        "    running_loss = 0\n",
        "\n",
        "    for X, y_true in train_loader:\n",
        "        optimizer.zero_grad()  # Initialise les gradients à zéro\n",
        "\n",
        "        X = X.to(device)  # on envoie les données X sur la GPU\n",
        "        y_true = y_true.to(device)  # on envoie les données Y sur la GPU\n",
        "\n",
        "        # Forward pass (on passe les données dans le modèle)\n",
        "        y_hat, _ = model(X)\n",
        "\n",
        "        loss = criterion(y_hat, y_true)  # Calcul de la perte\n",
        "\n",
        "        # Rétropropagation du gradient\n",
        "        loss.backward()  # Calcule les gradients par rétropropagation\n",
        "\n",
        "        optimizer.step()  # Met à jour les poids du modèle\n",
        "\n",
        "        running_loss += loss.item() * X.size(0)  # Met à jour la perte cumulée\n",
        "\n",
        "    running_loss /= len(train_loader.dataset)  # Calcul de la perte moyenne\n",
        "\n",
        "    return model, optimizer, running_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a45a054-7db2-4b48-a09c-eb075539a32d",
      "metadata": {
        "id": "8a45a054-7db2-4b48-a09c-eb075539a32d"
      },
      "source": [
        "---\n",
        "<span style='color:Green'>**Question**</span>\n",
        "\n",
        "En vous inspirant de la fonction train, completer la fonction validate, celle-ci permet de tester votre modèle:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cd110d6-1864-47f3-a3e3-bf7d2013c67b",
      "metadata": {
        "id": "1cd110d6-1864-47f3-a3e3-bf7d2013c67b"
      },
      "outputs": [],
      "source": [
        "# On créer la fonction qui permet de valider le modèle\n",
        "def validate(valid_loader, model, criterion):\n",
        "    '''\n",
        "    Function for the validation step of the training loop\n",
        "    '''\n",
        "\n",
        "    model.eval()  # Met le modèle en mode évaluation (désactive le dropout)\n",
        "    running_loss = 0\n",
        "\n",
        "    for X, y_true in valid_loader:\n",
        "\n",
        "        X = X.to(device)  # on envoie les données X sur la GPU\n",
        "        y_true = y_true.to(device)  # on envoie les données Y sur la GPU\n",
        "\n",
        "        # Forward pass and record loss\n",
        "        y_hat, _ = model(X)\n",
        "\n",
        "        loss = criterion(y_hat, y_true)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    running_loss /= len(valid_loader.dataset)\n",
        "    return model, running_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be2773f1-e042-4abf-92c2-df4e9347718b",
      "metadata": {
        "id": "be2773f1-e042-4abf-92c2-df4e9347718b"
      },
      "source": [
        "---\n",
        "<span style='color:Green'>**Question**</span>\n",
        "\n",
        "Ecrivez la fonction training_loop qui prend en paramètre le model, le criterion, l'optimizer, le train_loder, le valid_loader et le nombre d'épochs. Cette fonction permet de faire une étape de train et une étape de validate par epoch. Affichez l'erreur d'apprentissage et de validation toutes les 5 épochs.\n",
        "\n",
        "---\n",
        "---\n",
        "**Note**\n",
        "Lors de la validation, les gradients ne doivent pas être modifiés ([.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html)).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "223babf4-394e-4a85-92c6-6f509f1d88e7",
      "metadata": {
        "id": "223babf4-394e-4a85-92c6-6f509f1d88e7"
      },
      "outputs": [],
      "source": [
        "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, print_every=5):\n",
        "    '''\n",
        "    Training loop for the model\n",
        "    '''\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # Training\n",
        "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer)\n",
        "\n",
        "        # Validation\n",
        "        with torch.no_grad():  #Les gradients ne doivent pas être modifiés lors de la validation\n",
        "            model, valid_loss = validate(valid_loader, model, criterion)\n",
        "\n",
        "        # Affichage de l'erreur toutes les print_every épochs\n",
        "        if epoch % print_every == 0:\n",
        "            print(f'Epoch {epoch}/{epochs} ==> Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
        "\n",
        "    return model, optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "339b5830-25a9-4c6f-b5be-f0bd8ae7bffd",
      "metadata": {
        "id": "339b5830-25a9-4c6f-b5be-f0bd8ae7bffd"
      },
      "source": [
        "---\n",
        "<span style='color:Green'>**Question**</span>\n",
        "\n",
        "Définissez un [optimizer]( https://pytorch.org/docs/stable/optim.html#module-torch.optim) ainsi qu'une fonction de perte adaptés et justifiez votre choix.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5fd4c99-9969-4868-8adf-80230b71fa47",
      "metadata": {
        "id": "c5fd4c99-9969-4868-8adf-80230b71fa47"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Définir l'optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# Définir la fonction de perte\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjxxvQMV-lOf"
      },
      "source": [
        "---\n",
        "<span style='color:Green'>**Question**</span>\n",
        "\n",
        "Lancez l'entrainement de votre modèle en choisissant un nombre d'epoch judicieusement.\n",
        "\n",
        "---"
      ],
      "id": "XjxxvQMV-lOf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfea0f31-37e1-41b6-ae80-f2e110e024ae",
      "metadata": {
        "id": "cfea0f31-37e1-41b6-ae80-f2e110e024ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cfedd2f-dbee-49bd-8f1d-916e63698384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15 ==> Train Loss: 0.0288, Valid Loss: 0.0010\n",
            "Epoch 10/15 ==> Train Loss: 0.0165, Valid Loss: 0.0009\n",
            "Epoch 15/15 ==> Train Loss: 0.0114, Valid Loss: 0.0012\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 15\n",
        "\n",
        "model = net.to(device)\n",
        "\n",
        "# Définir l'optimizer (Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Définir la fonction de perte (CrossEntropyLoss)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Lancer l'entraînement\n",
        "model, optimizer = training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs=N_EPOCHS)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}